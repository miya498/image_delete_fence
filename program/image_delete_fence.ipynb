{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "834874067ef14a19a846df5eec26f048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc5ec45bf30b42b9b20db6389e66705d",
              "IPY_MODEL_b65932f24a87472bb172afc212a7a543",
              "IPY_MODEL_3b2b3b935a624d49acd1ec03de792534"
            ],
            "layout": "IPY_MODEL_0851ad98150f4a7489e26801cf4ab1b2"
          }
        },
        "dc5ec45bf30b42b9b20db6389e66705d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65abd0364be242caba823768c408b3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_53f8dd59f1104fe28b6e6d7a6386f885",
            "value": "100%"
          }
        },
        "b65932f24a87472bb172afc212a7a543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a98652d7054f82a605b1f3476f98fd",
            "max": 1376378527,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a95171b2aee047aa8ab52a4322e84877",
            "value": 1376378527
          }
        },
        "3b2b3b935a624d49acd1ec03de792534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a04cddf1f224df69b30852a0fb8bb4a",
            "placeholder": "​",
            "style": "IPY_MODEL_be957e884d194fb8ac63eb0ae259da73",
            "value": " 1.28G/1.28G [00:21&lt;00:00, 35.0MB/s]"
          }
        },
        "0851ad98150f4a7489e26801cf4ab1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65abd0364be242caba823768c408b3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f8dd59f1104fe28b6e6d7a6386f885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a98652d7054f82a605b1f3476f98fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95171b2aee047aa8ab52a4322e84877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a04cddf1f224df69b30852a0fb8bb4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be957e884d194fb8ac63eb0ae259da73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aace473c3644290a81523a8481e2693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c703bbdcf88d4aaaae104433bd71da1e",
              "IPY_MODEL_48b0c0828b974591b513c47f72f9aa86",
              "IPY_MODEL_eb7ba659104240dba8408c18ed616417"
            ],
            "layout": "IPY_MODEL_056e90e1ef774dfab628c6a78c5afe37"
          }
        },
        "c703bbdcf88d4aaaae104433bd71da1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ceb9a2513e4ae0a96557f5dfe4b453",
            "placeholder": "​",
            "style": "IPY_MODEL_ad28a661050c4e75a33adf3738186edf",
            "value": "100%"
          }
        },
        "48b0c0828b974591b513c47f72f9aa86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96103feeb4ad4a65aee1cc57f87d81d8",
            "max": 492757791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a50cbb917f347d2bbdfc1acf8820fe4",
            "value": 492757791
          }
        },
        "eb7ba659104240dba8408c18ed616417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff449b9aa254942a4ce4bc3e47fc14e",
            "placeholder": "​",
            "style": "IPY_MODEL_45c4dd3cffa24220bc29cdfdccc97dbc",
            "value": " 470M/470M [00:18&lt;00:00, 22.5MB/s]"
          }
        },
        "056e90e1ef774dfab628c6a78c5afe37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ceb9a2513e4ae0a96557f5dfe4b453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad28a661050c4e75a33adf3738186edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96103feeb4ad4a65aee1cc57f87d81d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a50cbb917f347d2bbdfc1acf8820fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ff449b9aa254942a4ce4bc3e47fc14e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c4dd3cffa24220bc29cdfdccc97dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "このコードは全てのtest画像のシーン名_input_base.jpgから1度の処理でまとめて画像修復します。\n",
        "このコード内の指示に従いtest_data内にシーン名_input_base.jpgのアップロードを左上の↑マークからお願いいたします。test_dataは添付したフォルダのファイル名で動きます。"
      ],
      "metadata": {
        "id": "4OtwRGol1urF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 各種インポート"
      ],
      "metadata": {
        "id": "2n5vrFov-mQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import torch\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "import glob\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "import copy"
      ],
      "metadata": {
        "id": "KOuTmwdLIJ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "S-HgtefLe7xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308e0da2-d660-4af0-b423-a68058bab6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data内にscene_o_0019_input_base.jpg等のscene名_input_base.jpgを全てアップロードする\n",
        "os.mkdir(\"/content/test_data\")"
      ],
      "metadata": {
        "id": "uu7IvyuLfOg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict_imgにファイルをフォルダごと分けて保存\n",
        "os.mkdir(\"/content/predict_img\")\n",
        "fnames = sorted(glob.glob(\"/content/test_data/*_input_base.jpg\"))\n",
        "for fname in fnames:\n",
        "    path_name = \"/content/predict_img/\" + fname.split(\"/\")[-1].replace(\"_input_base.jpg\", \"\")\n",
        "    os.mkdir(path_name)\n",
        "    shutil.copy(fname, path_name)\n",
        "\n",
        "!rm -r test_data  # test_dataの削除（不要なため）"
      ],
      "metadata": {
        "id": "_F7EhgQ9Yrej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習済みモデルのダウンロードと関数の定義"
      ],
      "metadata": {
        "id": "AMSMXSvU_o10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MiDaS深度推定\n",
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# MiDaS\n",
        "\n",
        "*Author: Intel ISL*\n",
        "\n",
        "**MiDaS models for computing relative depth from a single image.**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/midas_samples.png\" alt=\"alt\" width=\"50%\"/>\n",
        "\n",
        "\n",
        "### Model Description\n",
        "\n",
        "[MiDaS](https://arxiv.org/abs/1907.01341) computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using\n",
        "multi-objective optimization to ensure high quality on a wide range of inputs.\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "MiDaS depends on [timm](https://github.com/rwightman/pytorch-image-models). Install with"
      ],
      "metadata": {
        "id": "6XMcn_dDFsfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type_large = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "model_type_hybrid = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "\n",
        "midas_large = torch.hub.load(\"intel-isl/MiDaS\", model_type_large)\n",
        "midas_hybrid = torch.hub.load(\"intel-isl/MiDaS\", model_type_hybrid)\n",
        "\n",
        "# 深度推定large\n",
        "device_large = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# 深度推定hybrid\n",
        "device_hybrid = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# modelのtransformを指定\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.dpt_transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "834874067ef14a19a846df5eec26f048",
            "dc5ec45bf30b42b9b20db6389e66705d",
            "b65932f24a87472bb172afc212a7a543",
            "3b2b3b935a624d49acd1ec03de792534",
            "0851ad98150f4a7489e26801cf4ab1b2",
            "65abd0364be242caba823768c408b3a7",
            "53f8dd59f1104fe28b6e6d7a6386f885",
            "28a98652d7054f82a605b1f3476f98fd",
            "a95171b2aee047aa8ab52a4322e84877",
            "5a04cddf1f224df69b30852a0fb8bb4a",
            "be957e884d194fb8ac63eb0ae259da73",
            "2aace473c3644290a81523a8481e2693",
            "c703bbdcf88d4aaaae104433bd71da1e",
            "48b0c0828b974591b513c47f72f9aa86",
            "eb7ba659104240dba8408c18ed616417",
            "056e90e1ef774dfab628c6a78c5afe37",
            "87ceb9a2513e4ae0a96557f5dfe4b453",
            "ad28a661050c4e75a33adf3738186edf",
            "96103feeb4ad4a65aee1cc57f87d81d8",
            "5a50cbb917f347d2bbdfc1acf8820fe4",
            "0ff449b9aa254942a4ce4bc3e47fc14e",
            "45c4dd3cffa24220bc29cdfdccc97dbc"
          ]
        },
        "id": "GMdTDhFc_uX6",
        "outputId": "7df1cbfe-3628-43de-fb65-d8b9d54ea2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Downloading: \"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large-midas-2f21e586.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/1.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "834874067ef14a19a846df5eec26f048"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Downloading: \"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_hybrid-midas-501f0c75.pt\" to /root/.cache/torch/hub/checkpoints/dpt_hybrid-midas-501f0c75.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/470M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2aace473c3644290a81523a8481e2693"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "midas_large.to(device_large)\n",
        "midas_large.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72JM41vVESzI",
        "outputId": "748b8a90-10e0-47f6-f995-f09e7e11f130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (pre_logits): Identity()\n",
              "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "midas_hybrid.to(device_hybrid)\n",
        "midas_hybrid.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX6FsfKGFC3g",
        "outputId": "7c6af714-54b3-44f3-fafa-29132a43d551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): HybridEmbed(\n",
              "        (backbone): ResNetV2(\n",
              "          (stem): Sequential(\n",
              "            (conv): StdConv2dSame(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
              "            (norm): GroupNormAct(\n",
              "              32, 64, eps=1e-05, affine=True\n",
              "              (act): ReLU(inplace=True)\n",
              "            )\n",
              "            (pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
              "          )\n",
              "          (stages): Sequential(\n",
              "            (0): ResNetStage(\n",
              "              (blocks): Sequential(\n",
              "                (0): Bottleneck(\n",
              "                  (downsample): DownsampleConv(\n",
              "                    (conv): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (norm): GroupNormAct(\n",
              "                      32, 256, eps=1e-05, affine=True\n",
              "                      (act): Identity()\n",
              "                    )\n",
              "                  )\n",
              "                  (conv1): StdConv2dSame(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 64, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 64, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (1): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 64, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 64, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (2): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 64, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 64, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (1): ResNetStage(\n",
              "              (blocks): Sequential(\n",
              "                (0): Bottleneck(\n",
              "                  (downsample): DownsampleConv(\n",
              "                    (conv): StdConv2dSame(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (norm): GroupNormAct(\n",
              "                      32, 512, eps=1e-05, affine=True\n",
              "                      (act): Identity()\n",
              "                    )\n",
              "                  )\n",
              "                  (conv1): StdConv2dSame(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 512, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (1): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 512, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (2): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 512, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (3): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 128, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 512, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (2): ResNetStage(\n",
              "              (blocks): Sequential(\n",
              "                (0): Bottleneck(\n",
              "                  (downsample): DownsampleConv(\n",
              "                    (conv): StdConv2dSame(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (norm): GroupNormAct(\n",
              "                      32, 1024, eps=1e-05, affine=True\n",
              "                      (act): Identity()\n",
              "                    )\n",
              "                  )\n",
              "                  (conv1): StdConv2dSame(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (1): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (2): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (3): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (4): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (5): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (6): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (7): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "                (8): Bottleneck(\n",
              "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm1): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (norm2): GroupNormAct(\n",
              "                    32, 256, eps=1e-05, affine=True\n",
              "                    (act): ReLU(inplace=True)\n",
              "                  )\n",
              "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (norm3): GroupNormAct(\n",
              "                    32, 1024, eps=1e-05, affine=True\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (drop_path): Identity()\n",
              "                  (act3): ReLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (norm): Identity()\n",
              "          (head): ClassifierHead(\n",
              "            (global_pool): SelectAdaptivePool2d (pool_type=, flatten=Identity())\n",
              "            (fc): Identity()\n",
              "            (flatten): Identity()\n",
              "          )\n",
              "        )\n",
              "        (proj): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (pre_logits): Identity()\n",
              "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): Identity()\n",
              "      (1): Identity()\n",
              "      (2): Identity()\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): Identity()\n",
              "      (1): Identity()\n",
              "      (2): Identity()\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=1536, out_features=768, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=1536, out_features=768, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LaMa画像修復\n",
        "# 🦙 **LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions**\n",
        "\n",
        "[[Project page](https://saic-mdal.github.io/lama-project/)] [[GitHub](https://github.com/saic-mdal/lama)] [[arXiv](https://arxiv.org/abs/2109.07161)] [[Supplementary](https://ashukha.com/projects/lama_21/lama_supmat_2021.pdf)] [[BibTeX](https://senya-ashukha.github.io/projects/lama_21/paper.txt)]\n",
        "\n",
        "<p align=\"center\" \"font-size:30px;\">\n",
        "Our model generalizes surprisingly well to much higher resolutions (~2k❗️) than it saw during training (256x256), and achieves the excellent performance even in challenging scenarios, e.g. completion of periodic structures.\n",
        "</p>"
      ],
      "metadata": {
        "id": "Etua_sN7FvVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n> Cloning the repo')\n",
        "!git clone https://github.com/saic-mdal/lama.git\n",
        "\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -r lama/requirements.txt --quiet\n",
        "!pip install wget --quiet\n",
        "!pip install webdataset==0.1.103\n",
        "\n",
        "print('\\n> Changing the dir to:')\n",
        "%cd /content/lama\n",
        "\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o big-lama.zip\n",
        "!unzip big-lama.zip\n",
        "\n",
        "print('>fixing opencv')\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet\n",
        "\n",
        "import wget\n",
        "print('\\n> Init mask-drawing code')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSIsdUSp4nLA",
        "outputId": "0c870842-47da-4da5-e6fe-b245b87d6dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Cloning the repo\n",
            "Cloning into 'lama'...\n",
            "remote: Enumerating objects: 283, done.\u001b[K\n",
            "remote: Counting objects: 100% (283/283), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 283 (delta 73), reused 265 (delta 66), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (283/283), 6.49 MiB | 5.61 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n",
            "\n",
            "> Install dependencies\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 673 kB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 54.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 841 kB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 948 kB 38.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 43 kB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 56.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 17.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 39.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 176 kB 38.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 47.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 52.1 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting webdataset==0.1.103\n",
            "  Downloading webdataset-0.1.103-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: braceexpand in /usr/local/lib/python3.7/dist-packages (from webdataset==0.1.103) (0.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from webdataset==0.1.103) (1.21.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from webdataset==0.1.103) (6.0)\n",
            "Installing collected packages: webdataset\n",
            "  Attempting uninstall: webdataset\n",
            "    Found existing installation: webdataset 0.2.4\n",
            "    Uninstalling webdataset-0.2.4:\n",
            "      Successfully uninstalled webdataset-0.2.4\n",
            "Successfully installed webdataset-0.1.103\n",
            "\n",
            "> Changing the dir to:\n",
            "/content/lama\n",
            "\n",
            "> Download the model\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100  363M    0  363M    0     0  8157k      0 --:--:--  0:00:45 --:--:-- 9907k\n",
            "Archive:  big-lama.zip\n",
            "  inflating: big-lama/config.yaml    \n",
            "  inflating: big-lama/models/best.ckpt  \n",
            ">fixing opencv\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 51.0 MB/s \n",
            "\u001b[?25h\n",
            "> Init mask-drawing code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用する関数"
      ],
      "metadata": {
        "id": "qHKqOVXtfDUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def judge_fence_thick(depth_bit_img, gray_img):\n",
        "    judge_thick_img = np.zeros_like(depth_bit_img, dtype=\"float32\")\n",
        "    judge_thick_img = np.where(depth_bit_img == 255, gray_img, np.nan)\n",
        "    judge_thick = np.nanvar(judge_thick_img)  # nan以外の分散を計算\n",
        "    if judge_thick < 505:  # 分散がある閾値を超えたら太い柵とする\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "xZ6wDtMaGWLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mask:\n",
        "    def __init__(self, edge_img):\n",
        "        self.edge_img = edge_img\n",
        "\n",
        "\n",
        "    def judge_line(self, line_img, ratio=0.71):\n",
        "        judge_img = self.edge_img * line_img\n",
        "        if np.sum(judge_img) / np.sum(line_img) > ratio:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def get_mask(self):\n",
        "        mask_img = self.get_vertical_mask() + self.get_holizontal_mask()\n",
        "        mask_img[mask_img > 1] = 1\n",
        "        return mask_img\n",
        "\n",
        "\n",
        "    def get_vertical_mask(self):\n",
        "        cols, rows = self.edge_img.shape\n",
        "        mask_pre_img = np.zeros([cols, rows*3], dtype=\"uint8\")\n",
        "        for _ in range(2):\n",
        "            for row_low in range(0, rows, 5):\n",
        "                for shift in range(0, rows*2-row_low, 5):\n",
        "                    line_pre_img = np.zeros([cols, rows*3], dtype=\"uint8\")\n",
        "                    cv2.line(line_pre_img, (row_low+shift, 0), (rows+shift, cols-1), 1, 1)\n",
        "                    line_img = line_pre_img[:, rows:rows*2]\n",
        "                    if self.judge_line(line_img, 0.71):\n",
        "                        cv2.line(mask_pre_img, (row_low+shift, 0), (rows+shift, cols-1), 1, 10)\n",
        "            self.edge_img = cv2.flip(self.edge_img, 1)\n",
        "            mask_pre_img = cv2.flip(mask_pre_img, 1)\n",
        "        mask_img = mask_pre_img[:, rows:rows*2]\n",
        "        return mask_img\n",
        "\n",
        "\n",
        "    def get_holizontal_mask(self):\n",
        "        self.edge_img = cv2.rotate(self.edge_img, cv2.ROTATE_90_CLOCKWISE)\n",
        "        mask_img = self.get_vertical_mask()\n",
        "        self.edge_img = cv2.rotate(self.edge_img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "        mask_img = cv2.rotate(mask_img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "        return mask_img"
      ],
      "metadata": {
        "id": "9jlqg9C-c98p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# コード"
      ],
      "metadata": {
        "id": "nCGC-LijZZUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = sorted(glob.glob(\"/content/predict_img/*/*_input_base.jpg\"))"
      ],
      "metadata": {
        "id": "5S-nNNW3K4iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in fnames:\n",
        "    img = cv2.imread(fname)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 深度推定large\n",
        "    input_batch = transform(img).to(device_large)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas_large(input_batch)\n",
        "\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth_large = prediction.cpu().numpy()\n",
        "\n",
        "    # 深度推定hybrid\n",
        "    input_batch = transform(img).to(device_hybrid)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas_hybrid(input_batch)\n",
        "\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth_hybrid = prediction.cpu().numpy()\n",
        "\n",
        "\n",
        "    # 柵が太いか判定（柵が太い場合は後述のマスク処理がスキップされる）\n",
        "    depth_bit_img = np.zeros_like(depth_large, dtype=\"uint8\")\n",
        "\n",
        "    # 深度推定の画像の2値化\n",
        "    depth_bit_img[depth_large < 20] = 0\n",
        "    depth_bit_img[depth_large > 20] = 255\n",
        "\n",
        "    # グレースケール画像と深度推定の2値化画像で覆われた領域の分散を計算する\n",
        "    # 太い柵の場合は柵を覆うように深度推定の2値化画像ができるため、その領域のグレースケール画像の分散は小さくなる。\n",
        "    # 細い柵の場合は柵以外の領域も深度推定の2値化画像で覆われてしまうため、分散が大きくなる。\n",
        "    # ある分散の閾値今回は経験的に505以下のとき太い柵とする。\n",
        "    gray_img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
        "    fence_thick_flag = judge_fence_thick(depth_bit_img, gray_img)\n",
        "\n",
        "    if fence_thick_flag:\n",
        "        kernel = np.ones((5,5), np.uint8)\n",
        "        depth_bit_img = cv2.dilate(depth_bit_img, kernel, iterations=10)\n",
        "        mask_img = depth_bit_img\n",
        "        cv2.imwrite(fname.replace(\".jpg\", \"_mask_img.png\"), mask_img)\n",
        "        print(\"The fence is thick.\")\n",
        "    else:\n",
        "        # 深度推定後の画像のエッジ画像\n",
        "        blur_sigma = 5\n",
        "        kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]])  # 8近傍ラプラシアンフィルタ\n",
        "\n",
        "        # 深度推定large\n",
        "        depth_large_norm = cv2.normalize(depth_large, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "        depth_large_norm = cv2.GaussianBlur(depth_large_norm, (311, 311), blur_sigma)\n",
        "        edge_large = signal.convolve(depth_large_norm, kernel, mode=\"same\")\n",
        "\n",
        "        # 深度推定hybrid\n",
        "        depth_hybrid_norm = cv2.normalize(depth_hybrid, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "        depth_hybrid_norm = cv2.GaussianBlur(depth_hybrid_norm, (311, 311), blur_sigma)\n",
        "        edge_hybrid = signal.convolve(depth_hybrid_norm, kernel, mode=\"same\")\n",
        "\n",
        "        # エッジ画像を低画質で保存（計算高速化とmatplotlibの優れた画像補間（interaption=None）を利用するため）\n",
        "        # 302で割ると丁度縦横半分の画質になる\n",
        "        fig_row = edge_large.shape[1] / 302\n",
        "        fig_col = edge_large.shape[0] / 302\n",
        "\n",
        "        # 深度推定largeのedge画像を保存\n",
        "        fig, ax = plt.subplots(1, 1, dpi=100, figsize=(fig_row, fig_col))\n",
        "        ax.imshow(edge_large, interpolation=None, cmap=\"gray\", vmin=-0.001, vmax=0.001)\n",
        "        ax.axis(\"off\")\n",
        "        plt.savefig(\"edge_large.jpg\", bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # 深度推定hybridのedge画像を保存\n",
        "        fig, ax = plt.subplots(1, 1, dpi=100, figsize=(fig_row, fig_col))\n",
        "        ax.imshow(edge_hybrid, interpolation=None, cmap=\"gray\", vmin=-0.001, vmax=0.001)\n",
        "        ax.axis(\"off\")\n",
        "        plt.savefig(\"edge_hybrid.jpg\", bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # 保存したedge画像を開く\n",
        "        edge_large_img = cv2.imread(\"edge_large.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "        edge_hybrid_img = cv2.imread(\"edge_hybrid.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # 深度推定largeのエッジ画像を白黒反転して0-1に2値化\n",
        "        edge_large_bit_img = np.zeros_like(edge_large_img, dtype=\"uint8\")\n",
        "        edge_large_bit_img[edge_large_img < 127] = 1\n",
        "\n",
        "        # 深度推定hybridのエッジ画像を白黒反転して0-1に2値化\n",
        "        edge_hybrid_bit_img = np.zeros_like(edge_hybrid_img, dtype=\"uint8\")\n",
        "        edge_hybrid_bit_img[edge_hybrid_img < 127] = 1\n",
        "\n",
        "        # 深度推定large\n",
        "        mask_large = Mask(edge_large_bit_img)\n",
        "        mask_large_img = mask_large.get_mask()\n",
        "\n",
        "        # 深度推定hybrid\n",
        "        mask_hybrid = Mask(edge_hybrid_bit_img)\n",
        "        mask_hybrid_img = mask_hybrid.get_mask()\n",
        "\n",
        "        # 深度推定largeのマスクと深度推定hybridのマスクの結合\n",
        "        mask_img = mask_large_img + mask_hybrid_img\n",
        "        mask_img[mask_img > 1] = 1\n",
        "\n",
        "        # mask画像をinput_baseに合わせて拡大\n",
        "        mask_img = cv2.resize(mask_img, (img.shape[1], img.shape[0]))\n",
        "        mask_img[mask_img == 1] = 255  # 白(255)に置換\n",
        "\n",
        "        # マスク画像の保存（マスク画像の拡張子はpngでないと上手く動作しない）\n",
        "        cv2.imwrite(fname.replace(\".jpg\", \"_mask_img.png\"), mask_img)\n",
        "\n",
        "    # LaMaによる画像修復\n",
        "    path_name = fname.replace(\"/\" + fname.split(\"/\")[-1], \"\")\n",
        "    print(f\"inpainting {path_name}\")\n",
        "    if '.jpeg' in fname:\n",
        "        !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$path_name outdir=/content/inpainting_img dataset.img_suffix=.jpeg > /dev/null\n",
        "    elif '.jpg' in fname:\n",
        "        !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$path_name outdir=/content/inpainting_img  dataset.img_suffix=.jpg > /dev/null\n",
        "    elif '.png' in fname:\n",
        "        !PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$path_name outdir=/content/inpainting_img  dataset.img_suffix=.png > /dev/null\n",
        "    else:\n",
        "        print(f'Error: unknown suffix .{fname.split(\".\")[-1]} use [.png, .jpeg, .jpg]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJIxxra9ncd8",
        "outputId": "668fa92d-13d0-45ba-fc9e-f845e1e4a4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inpainting /content/predict_img/scene_m_0002\n",
            "100% 1/1 [00:02<00:00,  2.33s/it]\n",
            "inpainting /content/predict_img/scene_m_0003\n",
            "100% 1/1 [00:02<00:00,  2.27s/it]\n",
            "inpainting /content/predict_img/scene_m_0021\n",
            "100% 1/1 [00:02<00:00,  2.33s/it]\n",
            "inpainting /content/predict_img/scene_m_0024\n",
            "100% 1/1 [00:02<00:00,  2.27s/it]\n",
            "inpainting /content/predict_img/scene_m_0026\n",
            "100% 1/1 [00:02<00:00,  2.33s/it]\n",
            "The fence is thick.\n",
            "inpainting /content/predict_img/scene_m_0033\n",
            "100% 1/1 [00:02<00:00,  2.24s/it]\n",
            "inpainting /content/predict_img/scene_m_0046\n",
            "100% 1/1 [00:02<00:00,  2.31s/it]\n",
            "inpainting /content/predict_img/scene_o_0001\n",
            "100% 1/1 [00:02<00:00,  2.27s/it]\n",
            "The fence is thick.\n",
            "inpainting /content/predict_img/scene_o_0019\n",
            "100% 1/1 [00:02<00:00,  2.26s/it]\n",
            "inpainting /content/predict_img/scene_o_0022\n",
            "100% 1/1 [00:02<00:00,  2.31s/it]\n",
            "inpainting /content/predict_img/scene_u_0019\n",
            "100% 1/1 [00:02<00:00,  2.28s/it]\n",
            "inpainting /content/predict_img/scene_u_0020\n",
            "100% 1/1 [00:02<00:00,  2.32s/it]\n",
            "inpainting /content/predict_img/scene_u_0040\n",
            "100% 1/1 [00:02<00:00,  2.26s/it]\n",
            "inpainting /content/predict_img/scene_u_0060\n",
            "100% 1/1 [00:02<00:00,  2.19s/it]\n",
            "inpainting /content/predict_img/scene_u_0075\n",
            "100% 1/1 [00:02<00:00,  2.14s/it]\n",
            "inpainting /content/predict_img/scene_u_0082\n",
            "100% 1/1 [00:02<00:00,  2.34s/it]\n",
            "The fence is thick.\n",
            "inpainting /content/predict_img/scene_u_0084\n",
            "100% 1/1 [00:02<00:00,  2.26s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip化してファイルを取得（google colabの左のフォルダマークの縦に3つドットが書かれているところをクリックすると保存できます。）\n",
        "!zip -r /content/inpainting_img.zip /content/inpainting_img\n",
        "!zip -r /content/predict_img.zip /content/predict_img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rghDhKs0tsT8",
        "outputId": "b6dbd56e-1654-46c4-ce91-ef26c6b7688b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/inpainting_img/ (stored 0%)\n",
            "  adding: content/inpainting_img/scene_m_0026_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_m_0033_input_base_mask_img.png (deflated 2%)\n",
            "  adding: content/inpainting_img/scene_u_0082_input_base_mask_img.png (deflated 2%)\n",
            "  adding: content/inpainting_img/scene_o_0019_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_u_0060_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_u_0084_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_m_0002_input_base_mask_img.png (deflated 2%)\n",
            "  adding: content/inpainting_img/scene_u_0020_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_m_0024_input_base_mask_img.png (deflated 3%)\n",
            "  adding: content/inpainting_img/scene_m_0046_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_m_0003_input_base_mask_img.png (deflated 2%)\n",
            "  adding: content/inpainting_img/scene_u_0040_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_u_0075_input_base_mask_img.png (deflated 2%)\n",
            "  adding: content/inpainting_img/scene_m_0021_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_u_0019_input_base_mask_img.png (deflated 1%)\n",
            "  adding: content/inpainting_img/scene_o_0022_input_base_mask_img.png (deflated 3%)\n",
            "  adding: content/inpainting_img/scene_o_0001_input_base_mask_img.png (deflated 2%)\n",
            "  adding: content/predict_img/ (stored 0%)\n",
            "  adding: content/predict_img/scene_o_0001/ (stored 0%)\n",
            "  adding: content/predict_img/scene_o_0001/scene_o_0001_input_base.jpg (deflated 1%)\n",
            "  adding: content/predict_img/scene_o_0001/scene_o_0001_input_base_mask_img.png (deflated 53%)\n",
            "  adding: content/predict_img/scene_m_0033/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0033/scene_m_0033_input_base_mask_img.png (deflated 24%)\n",
            "  adding: content/predict_img/scene_m_0033/scene_m_0033_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_m_0021/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0021/scene_m_0021_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_m_0021/scene_m_0021_input_base_mask_img.png (deflated 58%)\n",
            "  adding: content/predict_img/scene_u_0060/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0060/scene_u_0060_input_base_mask_img.png (deflated 16%)\n",
            "  adding: content/predict_img/scene_u_0060/scene_u_0060_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0082/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0082/scene_u_0082_input_base_mask_img.png (deflated 63%)\n",
            "  adding: content/predict_img/scene_u_0082/scene_u_0082_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0040/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0040/scene_u_0040_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0040/scene_u_0040_input_base_mask_img.png (deflated 63%)\n",
            "  adding: content/predict_img/scene_m_0046/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0046/scene_m_0046_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_m_0046/scene_m_0046_input_base_mask_img.png (deflated 16%)\n",
            "  adding: content/predict_img/scene_u_0075/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0075/scene_u_0075_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0075/scene_u_0075_input_base_mask_img.png (deflated 19%)\n",
            "  adding: content/predict_img/scene_o_0019/ (stored 0%)\n",
            "  adding: content/predict_img/scene_o_0019/scene_o_0019_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_o_0019/scene_o_0019_input_base_mask_img.png (deflated 59%)\n",
            "  adding: content/predict_img/scene_m_0024/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0024/scene_m_0024_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_m_0024/scene_m_0024_input_base_mask_img.png (deflated 63%)\n",
            "  adding: content/predict_img/scene_u_0019/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0019/scene_u_0019_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0019/scene_u_0019_input_base_mask_img.png (deflated 26%)\n",
            "  adding: content/predict_img/scene_u_0084/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0084/scene_u_0084_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0084/scene_u_0084_input_base_mask_img.png (deflated 59%)\n",
            "  adding: content/predict_img/scene_m_0003/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0003/scene_m_0003_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_m_0003/scene_m_0003_input_base_mask_img.png (deflated 58%)\n",
            "  adding: content/predict_img/scene_u_0020/ (stored 0%)\n",
            "  adding: content/predict_img/scene_u_0020/scene_u_0020_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_u_0020/scene_u_0020_input_base_mask_img.png (deflated 30%)\n",
            "  adding: content/predict_img/scene_m_0002/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0002/scene_m_0002_input_base_mask_img.png (deflated 57%)\n",
            "  adding: content/predict_img/scene_m_0002/scene_m_0002_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_o_0022/ (stored 0%)\n",
            "  adding: content/predict_img/scene_o_0022/scene_o_0022_input_base.jpg (deflated 0%)\n",
            "  adding: content/predict_img/scene_o_0022/scene_o_0022_input_base_mask_img.png (deflated 67%)\n",
            "  adding: content/predict_img/scene_m_0026/ (stored 0%)\n",
            "  adding: content/predict_img/scene_m_0026/scene_m_0026_input_base_mask_img.png (deflated 63%)\n",
            "  adding: content/predict_img/scene_m_0026/scene_m_0026_input_base.jpg (deflated 0%)\n"
          ]
        }
      ]
    }
  ]
}